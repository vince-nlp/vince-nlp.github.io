<html>
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<title>LawBench: Benchmarking Legal Knowledge of Large Language Models</title>
</head>
<body>

<h3>LawBench: Benchmarking Legal Knowledge of Large Language Models</h3>
 Zhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Alan Huang, Songyang Zhang, Kai Chen, Zhixin Yin, Zongwen Shen, Jidong Ge, and Vincent Ng
<br>
<i>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</i>, <!-- pp. 8114-8122, --> 2024. 


<p>Click here for the <a href="emnlp24-law.pdf">PDF</a> version. 
<!-- The talk slides are available <a href="../talks.html#acl17">here</a>. -->

<p>
<h3>Abstract</h3>

We present LawBench, the first evaluation benchmark composed of 20 tasks aimed to assess the ability of large language models (LLMs) to perform Chinese legal-related tasks. LawBench is meticulously crafted to enable precise assessment of LLMs' legal capabilities from three cognitive levels that correspond to the widely accepted Bloom's cognitive taxonomy. Using LawBench, we present a comprehensive evaluation of 21 popular LLMs and the first comparative analysis of the empirical results in order to reveal their relative strengths and weaknesses. All data, model predictions and evaluation code are accessible from <a href="https://github.com/open-compass/LawBench">this</a> link. 

<p>
<h3>BibTeX entry</h3>

<pre>
@InProceedings{Fei+etal:24a,
  author = {},
  title = {LawBench: Benchmarking Legal Knowledge of Large Language Models},
  booktitle = {Proceedings of the 2024 Empirical Methods in Natural Language Processing},
<!--  pages = {8114--8122}, -->
  year = 2024}
</pre>
<br>

<!--
<p align="center"><img src="emnlp13-poster.jpg" alt="poster" width="100%";></p>
-->
<hr>
</body>

</html>
