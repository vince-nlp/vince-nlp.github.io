<html>
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<title>Joint Learning for Event Coreference Resolution</title>
</head>
<body>

<h3>Joint Learning for Event Coreference Resolution</h3>
Jing Lu and Vincent Ng.
<br>
<i>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</i>, pp. 90-101, 2017. 


<p>Click here for the 
<!-- <a href="acl17.ps">PostScript</a> or  -->
<!-- <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9925/9528"> -->
<a href="acl17.pdf">PDF</a> version. 
The talk slides are available <a href="../talks.html#acl17">here</a>. 

<p>
<h3>Abstract</h3>

While joint models have been developed for many NLP tasks, the vast majority of
event coreference resolvers, including the top-performing resolvers competing in the
recent TAC KBP 2016 Event Nugget Detection and Coreference task, are pipelinebased,
where the propagation of errors from the trigger detection component to the event coreference component is a major performance limiting factor. To address
this problem, we propose a model for jointly learning event coreference, trigger
detection, and event anaphoricity. Our joint model is novel in its choice of tasks
and its features for capturing cross-task interactions. To our knowledge, this is
the first attempt to train a mention-ranking model and employ event anaphoricity for
event coreference. Our model achieves the best results to date on the KBP 2016 English
and Chinese datasets.

<p>
<h3>BibTeX entry</h3>

<pre>
@InProceedings{Lu+Ng:17a,
  author = {Jing Lu and Vincent Ng},
  title = {Joint Learning for Event Coreference Resolution},
  booktitle = {Proceedings of 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages = {90--101}, 
  year = 2017}
</pre>
<br>

<!--
<p align="center"><img src="emnlp13-poster.jpg" alt="poster" width="100%";></p>
-->
<hr>
</body>

</html>
